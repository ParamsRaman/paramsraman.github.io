---
layout: single
classes: wide
title: Research
author_profile: true
permalink: /publications/
---

### Publications
1. <b>nuSAM: Memory-Efficient Sharpness-Aware Minimization via Nuclear Norm Constraints</b>   
Thomas Pethick, **Parameswaran Raman**, Lenon Minorics, Mingyi Hong, Shoham Sabach, Volkan Cevher
*Transactions on Machine Learning Research, 2025*
[<button type="button" class="btn btn-info">Paper</button>](https://openreview.net/pdf?id=V6ia5hWIMD)

1. <b>HLAT: High-quality Large Language Model Pre-trained on AWS Trainium</b>   
Haozheng Fan, Hao Zhou, Guangtai Huang, **Parameswaran Raman**, Xinwei Fu, Gaurav Gupta, Dhananjay Ram, Yida Wang, Jun Huan
*IEEE International Conference on Big Data, 2024*
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2404.10630)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/awslabs/HLAT)
[<button type="button" class="btn btn-info">Blog</button>](https://aws.amazon.com/blogs/machine-learning/end-to-end-llm-training-on-instance-clusters-with-over-100-nodes-using-aws-trainium/)

1. <b>EMC^2: Efficient MCMC Negative Sampling for Contrastive Learning with Global Convergence</b>   
Chung-Yiu Yau, Hoi-To Wai, **Parameswaran Raman**, Soumajyoti Sarkar, Mingyi Hong
*International Conference on Machine Learning (ICML), 2024*
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2404.10575)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/amazon-science/contrastive_emc2)
[<button type="button" class="btn btn-info">Poster</button>](/files/EMC_ContrastiveLearning_poster_ICML_2024.png)

1. <b>Variance-reduced Zero Order Optimization for LLM Fine-tuning</b>   
Tanmay Gautam, Youngsuk Park, Hou Zhou, **Parameswaran Raman**, Wooseok Ha
*International Conference on Machine Learning (ICML), 2024*
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2404.08080)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/amazon-science/mezo_svrg)
[<button type="button" class="btn btn-info">Poster</button>](/files/MeZO_SVRG_poster_ICML_2024.png)

1. <b>MADA: Meta-Adaptive Optimizers through hyper-gradient Descent</b>   
Kaan Ozkara, Can Karakus, **Parameswaran Raman**, Mingyi Hong, Shoham Sabach, Branislav Kveton, Volkan Cevher  *International Conference on Machine Learning (ICML), 2024*
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2401.08893)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/amazon-science/mada_optimizer_search)
[<button type="button" class="btn btn-info">Slides</button>](/files/MADA_final_presentation.pdf)
[<button type="button" class="btn btn-info">Poster</button>](/files/MADA_poster_ICML_2024.png)

1. <b>Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free Convergence Rate</b>   
Ruichen Jiang, **Parameswaran Raman**, Shoham Sabach, Aryan Mokhtari, Mingyi Hong, Volkan Cevher
*International Conference on Artificial Intelligence and Statistics (AISTATS), 2024*
[<button type="button" class="btn btn-info">Paper</button>](https://arxiv.org/abs/2401.03058)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/amazon-science/krylov-cubic-regularized-newton)
[<button type="button" class="btn btn-info">Slides</button>](/files/Slides_Krylov_CRN.pdf)
[<button type="button" class="btn btn-info">Poster</button>](/files/Krylov_CRN_poster_AISTATS_2024.pdf)

1. <b>Contractive Error Feedback for Gradient Compression</b>   
Bingcong Li, Shuai Zheng, **Parameswaran Raman**, Anshumali Shrivastava, Georgios B. Giannakis
*Preprint, 2022*
[<button type="button" class="btn btn-info">ArXiv</button>](https://arxiv.org/abs/2312.08538)
[<button type="button" class="btn btn-info">Code</button>](https://github.com/BingcongLi/ConEF)
[<button type="button" class="btn btn-info">Slides</button>](/files/ConEF_final_presentation.pdf)

1. <b>DS-FACTO: Doubly Separable Factorization Machines</b>   
**Parameswaran Raman**, S.V.N. Vishwanathan
[<button type="button" class="btn btn-info">ArXiv</button>](https://arxiv.org/abs/2004.13940)
[<button type="button" class="btn btn-info">Slides</button>](/files/dsfacto_slides.pdf)

1. <b>Scaling Multinomial Logistic Regression via Hybrid Parallelism</b>    
**Parameswaran Raman**, Sriram Srinivasan, Shin Matsushima, Xinhua Zhang, Hyokun Yun, S.V.N. Vishwanathan
*ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), 2019*
Accepted as Oral Presentation (9.16 % acceptance rate).
[<button type="button" class="btn btn-info">Paper</button>](/files/mlr-kdd19.pdf)
[<button type="button" class="btn btn-info">Code</button>](https://bitbucket.org/params/dsmlr)
[<button type="button" class="btn btn-info">Promo Video</button>](https://www.youtube.com/watch?v=1YdTSldKVno)
[<button type="button" class="btn btn-info">Slides</button>](/files/dsmlr_KDD19_slides_short.pdf)
[<button type="button" class="btn btn-info">Poster</button>](/files/dsmlr_KDD19_poster.pdf)

1. <b>Extreme Stochastic Variational Inference: Distributed and Asynchronous</b>   
**Parameswaran Raman***, Jiong Zhang*, Shihao Ji, Hsiang-Fu Yu, S.V.N. Vishwanathan, Inderjit S. Dhillon (* equally contributed)
*International Conference on Artificial Intelligence and Statistics (AISTATS), 2019*
[<button type="button" class="btn btn-info">Paper</button>](/files/esvi-aistats19.pdf)
[<button type="button" class="btn btn-info">Slides</button>](/files/esvi-talk-labmeeting.pdf)
[<button type="button" class="btn btn-info">Poster</button>](/files/esvi-poster.pdf)

1. <b>Ranking via Robust Binary Classification</b>   
Hyokun Yun, **Parameswaran Raman**, S.V.N. Vishwanathan
*Advances in Neural Information Processing Systems (NeurIPS), 2014*
[<button type="button" class="btn btn-info">Paper</button>](https://proceedings.neurips.cc/paper_files/paper/2014/file/3d779cae2d46cf6a8a99a35ba4167977-Paper.pdf)
[<button type="button" class="btn btn-info">Poster</button>](/files/RoBiRank_Poster.pdf)
[<button type="button" class="btn btn-info">Code</button>](https://bitbucket.org/d_ijk_stra/robirank)

1. <b>Optimization on the surface of the (Hyper)-Sphere</b>   
**Parameswaran Raman**, Jiasen Yang
*Tech Report, 2014*
[<button type="button" class="btn btn-info">ArXiv</button>](https://arxiv.org/abs/1909.06463)

1. <b>Relevancy Prediction of Micro-blog Questions in an Educational Setting</b>   
Mariheida Córdova Sánchez, **Parameswaran Raman**, Luo Si, Jason Fish
*Proceedings of the 7th International Conference on Educational Data Mining (EDM), 2014*
[<button type="button" class="btn btn-info">ArXiv</button>](/files/Poster_EDM_2014.pdf)
{: style="font-size:0.7em;"}

### Open Source Software
* [<button type="button" class="btn btn-info">DS-MLR</button>](https://bitbucket.org/params/dsmlr)
Hybrid-Parallel stochastic optimization algorithm for Multinomial Logistic Regression with large number of data points and large number of classes.
* [<button type="button" class="btn btn-info">ESVI</button>](https://bitbucket.org/params/dmixmodels)
Hybrid-Parallel variational inference algorithm for Mixture of Exponential Family models with large number of data points and mixture components.
* [<button type="button" class="btn btn-info">RoBiRank</button>](https://bitbucket.org/d_ijk_stra/robirank)
Robust and scalable ranking algorithm for Large Data (both learning to rank and latent collaborative retrieval).
{: style="font-size:0.7em;"}

Code is released under the Apache License ver 2.0.
{: style="font-size:0.7em;"}

### PhD Thesis
**Hybrid-Parallel Parameter Estimation for Bayesian and Frequentist Models**
[<button type="button" class="btn btn-info">Thesis</button>](/files/params_phd_thesis.pdf)
[<button type="button" class="btn btn-info">Slides</button>](/files/phd_defense_slides.pdf)

<!--Distributed parameter estimation algorithms in machine learning follow two main flavors: data parallel, where the data is distributed across multiple workers and model parallel, where the model parameters are partitioned across multiple workers. The main limitation of the first approach is that the model parameters need to be replicated on every machine. This is problematic when the number of parameters is very large, and hence cannot fit in a single machine. The drawback of the latter approach is that the data needs to be replicated on each machine. In this thesis, I propose Hybrid-Parallelism, an approach that allows us to partition both, the data as well as the model parameters
simultaneously. As a result, each worker only needs access to a subset of the data and a subset of the parameters while performing parameter updates. I also develop novel reformulations for various large-scale problems which allow us to achieve such Hybrid-Parallelism. My work broadly covers four types of opular models: (1) Multinomial Logistic Regression (2) Mixture of Exponential Families, (3) Latent Collaborative Retrieval, and (4) Factorization Machines. In all cases, I show how to exploit the access pattern of parameter updates to derive Hybrid-Parallel asynchronous algorithms.-->

Distributed parameter estimation algorithms in machine learning follow two main flavors: data parallel, where the data is distributed across multiple workers and model parallel, where the model parameters are partitioned across multiple workers. Neither of these are desirable approaches since they lead to replicating either data or model parameters. In order to scale to arbitrary sizes, it is imperative to distribute both, however this is not possible in many machine learning problems due to the tightly coupled optimization problem (for e.g. log-partition function in multinomial logistic regression). In this thesis, I develop alternative reformulations for various large-scale machine learning problems in order to enable Hybrid-Parallelism (simultaneous data and model parallelism). Morever, since each worker only needs access to a subset of the data and a subset of the parameters while performing parameter updates, bulk synchronization can be avoided. I demonstrate how to apply these ideas to four types of popular models: (1) [Multinomial Logistic Regression for large # of classes and examples](/files/dsmlr_KDD19_poster.pdf) (2) [Mixture of Exponential Families for large # of examples and clusters](/files/esvi-poster.pdf), (3) [Latent Collaborative Retrieval for large # of users and items](/files/RoBiRank_Poster.pdf), and (4) [Factorization Machines for large number of examples and features](https://arxiv.org/abs/2004.13940).
{: style="font-size:0.7em;"}

### Other publications during Masters and prior
1. <b>Participatory Design Process for an In-Vehicle Affect Detection and Regulation System for Various Drivers</b>   
Myounghoon "Philart" Jeon, **Parameswaran Raman**, Jung-Bin Yim, J B, Bruce N. Walker
*Proceedings of the 13th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS), 2011*[<button type="button" class="btn btn-info">Paper</button>](/files/assets11_jeon.pdf)

1. <b>ENGIN (Exploring Next Generation IN-vehicle INterfaces): Drawing a New Conceptual Framework through Iterative Participatory Processes</b>   
Myounghoon "Philart" Jeon, Jonathan Schuett, Jung-Bin Yim, **Parameswaran Raman**, Bruce N. Walker
*Proceedings of the 3rd International Conference on Automotive User Interfaces and Interactive Vehicular Applications (AutomotiveUI), 2011*
[<button type="button" class="btn btn-info">Paper</button>](/files/ENGIN_AutomotiveUI2011_Philart.pdf)

1. <b>Advanced Auditory Menus for Universal Access to Electronic Devices</b>   
Myounghoon "Philart" Jeon, Benjamin Davison, Jeff Wilson, **Parameswaran Raman**, Bruce N. Walker
*Proceedings of International Technology & Persons with Disabilities Conference (CSUN), 2010*
[<button type="button" class="btn btn-info">Paper</button>](/files/CSUN2010_ExtendedAbstract_091102-BNW.pdf)

1. <b>Reducing repetitive development tasks in auditory menu displays with the auditory menu library</b>   
**Parameswaran Raman**, Benjamin Davison, Myounghoon "Philart" Jeon, Bruce N. Walker
*Proceedings of the 16th International Conference on Auditory Display (ICAD), 2010*
[<button type="button" class="btn btn-info">Paper</button>](/files/AML_ICAD_2010.pdf)

1. <b>Target Score Prediction in the game of Cricket</b>   
Sethuraman K, **Parameswaran Raman**, Vijay Ramakrishnan
*Tech Report, 2010*
[<button type="button" class="btn btn-info">Paper</button>](/files/ML_Project_CS7641_report.pdf)
[<button type="button" class="btn btn-info">Slides</button>](/files/ML_Project_CS7641_slides.pdf)

1. <b>PiX-C, Pictures: Express & Communicate (Augmenting Communication with Visual Input for Children in the Autism Spectrum)</b>   
Narayanan Ramakrishnan, **Parameswaran Raman**, Manohar Ganesan, Gourab Kar, Gregory D. Abowd
*Poster at 23rd ACM Symposium on User Interface Software and Technology (UIST), 2010*
[<button type="button" class="btn btn-info">Poster</button>](/files/PiX-C_Poster.pdf)
[<button type="button" class="btn btn-info">Slides</button>](/files/NLP_TermProject.pdf)

1. <b>PINE-guided cache replacement policy for location-dependent data in mobile environment</b>   
Mary Magdalene Jane, **Parameswaran Raman**, Nadarajan R, Maytham Safar
*Proceedings of the First international conference on Pervasive Technologies Related to Assistive Environments (PETRA), 2008*
[<button type="button" class="btn btn-info">Paper</button>](/files/PINE.pdf)

1. <b>Weighted Angular Distance Based Cache Replacement Strategy for Location-Dependent Data in Wireless Environment</b>   
**Parameswaran Raman**, Raghavendra Prasad, Nadarajan R, Mary Magdalene Jane
*Proceedings of the DCCA Conference, Jordan, 2007*
[<button type="button" class="btn btn-info">Paper</button>](/files/WIDAAP_cameraready_Jordan.pdf)
{: style="font-size:0.7em;"}

<!--span style="font-size=0.75em;font-style:italic;font-weight:bold;"></span-->
