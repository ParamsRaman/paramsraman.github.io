---
layout: default
section: home
title: "Parameswaran Raman: Academic Homepage"
---

<div class="row">
  <div class="col-sm-3 col-md-2">
    <img src="static/params_pongal.png" class="img-thumbnail" width="200px"
    style="margin-top: 10px; margin-bottom: 15px">
  </div>
  <div class="col-sm-9 col-md-10">
    <h1 style="font-size: 25px">Parameswaran Raman</h1>
    <p>
    <span style="color: #000000; font-family: Helvetica Neue, Helvetica, sans-serif;
      font-weight:300">
      Ph.D. Candidate, Computer Science<br>
      Machine Learning and Intelligence Lab (Engineering 2, 489)<br>
      University of California, Santa Cruz (Transferred from Purdue University
      in 2014)<br>
      Email: params AT ucsc DOT edu
    </span>
    </p>
  </div>
</div>

<!--p><span style="background: #FFFF33">*** UPDATE: I am currently actively looking for full-time positions in the industry!</span><br-->

<span style="color: #000000"><b>I am in the job market this academic year
    (2019-2020).</b></span> <br><br>

<!--h2>Bio</h2-->
<p align="justify"> I am a final year Ph.D. candidate in Computer Science at University of
California, Santa Cruz advised by Prof. <a
  href="http://www.stat.purdue.edu/~vishy/"> S.V.N. Vishwanathan</a>. My
  research interests lie at the intersection of <b>Optimization</b> and
  <b>Large-Scale Machine Learning</b>, with applications in areas such as
  <i>Ranking, Recommender Systems</i>, <i> Extreme Classification</i> (multi-class or multi-label 
  involving huge number of data points and classes/labels), <i>Extreme
    Clustering</i> (huge number of
  data points and clusters) and <i>Deep Learning</i>. Other interests
  include <b>Scalable Bayesian Inference</b> for <b> Graphical Models</b>. 

<br><br>
My thesis work has focussed on:
<ul>
  <li> Developing reformulations for a wide spectrum of frequentist and bayesian models 
    to help distribute computation across machines more efficiently (de-centralize both data as well as
    model parameters simultaneously to achieve <i>Hybrid Parallelism</i>) by using novel algorithmic/statistical/computational techniques, 
  <li> Developing and implementing "asynchronous" distributed stochastic optimizers to solve the reformulations.
</ul>

<!--b>I have experience designing and implementing parallel optimization/inference algorithms 
in distributed memory settings, for a variety of large-scale
supervised and unsupervised machine learning models.<br><br>

I am very excited about applying advances from algorithms/numerical linear
algebra and systems/high-performance computing areas to develop computationally
efficient machine learning algorithms that can deal with massive datasets.<b-->

During the course of my Ph.D., I have also spent wonderful summers interning at
<i>LinkedIn</i> (2014), <i>Microsoft Research CISL Lab</i> (2015), <i>Adobe
  Research</i> (2016) and <i>Amazon AI</i> (2017) working on diverse interesting problems in machine learning. 
Before joining my Ph.D., I worked at <i>Yahoo!</i> (2011-2013) in the Personalization
  Group on applying machine learning and NLP to Entity Matching, Entity Extraction and Knowledge Graph problems. 
  I got my masters degree in Computer Science at <i>Georgia
    Tech</i> (2011). I worked in the Sonification Lab of Georgia Tech, with
  Prof. Bruce Walker in developing auditory and non-traditional interfaces for Human Computer Interaction.
  <br> <br>
</p>

<p> <span style="background:#eeffee">More details can be found in my </span> <a
    href="static/pub/params-cv.pdf" style="color:#FF0000">[CV]</a>. <br> 
<!--span>An overview of my research can be found <a href="static/pub/research-proposal.pdf">here (long version)</a> and <a href="static/pub/research-summary.pdf">here (short version)</a>. </span-->
</p>

<br>
<!--h2>Industry Experience</h2>
<ul>
  <li style="padding: 5px 5px;"> 
    Applied Scientist Intern, <b> Amazon AI
      </b>, Palo Alto (Summer 2017)<br>
      <i>Researched and implemented temporal video recommendation models using
        Deep Neural Networks.</i> 
  </li>
  <li style="padding: 5px 5px;"> 
    Research Intern, <b> Adobe Research </b>, San Jose (Summer 2016)<br>
       <i>Developed models to cluster user-behavior in Adobe analytics data using
         both click (user url) as well as content information (user
         meta-data).</i>
  </li>
  <li style="padding: 5px 5px;"> 
    Research Intern, <b> Microsoft Research (Cloud Information and Services
      Lab)</b>, Mountain View (Summer 2015)<br>
    <i>Researched the problem of extrapolating learning curves in machine
       learning. Developed, implemented and evaluated a new prototype to perform non-linear
       curve-fitting of predictors using small bites of data.</i> 
  </li>
  <li style="padding: 5px 5px;"> 
    Research Intern, <b> LinkedIn (Search Relevance)</b>, Mountain View (Summer 2014)<br>
    <i>Explored machine learning methods to resolve issues of sample bias and position 
       bias present in learning to rank systems with implicit feedback. Proposed
       a new ranking framework to combine models incrementally. </i>
  </li>
  <li style="padding: 5px 5px;"> 
    Software Engineer, <b> Yahoo! </b>, Sunnyvale (July 2011 - July 2013) <br>
    <i> Worked in the Personalization Group on projects related to Entity
      Detection, Entity Matching and Resolution,
      Knowledge Graph. Worked in the Hadoop Team contributing to the Open-Source
      project <a href="https://oozie.apache.org/">Oozie</a> (Yahoo!'s Hadoop Workflow Scheduler).</i>
  </li>
  <li style="padding: 5px 5px;"> 
    Software Engineering Intern, <b> Intel Corporation </b>, Chandler (Summer
    2010) <br>
    <i>Developed a searching and indexing infrastructure to help silicon engineers find relevant product design
information. Gathered requirements, developed and tested the system, and
deployed in production.</i>
  </li>
  <li style="padding: 5px 5px;"> 
    Application Developer, <b> ThoughtWorks </b>, Bangalore (June 2008 - July
    2009)<br>
    <i>Designed and implemented web-services for the UK train ticket retailing
      system - <a href="http://thetrainline.com">thetrainline.com</a>.</i>
  </li>
</ul-->

<br>
<hr>
<h2>Recent </h2>
<ul>
    <li style="padding: 5px 5px;"> 
        12/2019: Defended my Ph.D. dissertation on <span style="background:
        #eeffee"> Hybrid-Parallel Parameter Estimation for Bayesian and
        Frequentist Models </span>, <a
          href="https://www.slideshare.net/secret/ozBtkzphmZTRNI"
          style="color:#FF0000">Slides</a> </li>
    <li style="padding: 5px 5px;"> 
        08/2019: Presented our work on <span style="background:
        #eeffee"> Scaling Multinomial Logistic Regression via Hybrid-Parallelism </span> 
        at KDD 2019, <a
          href="https://people.ucsc.edu/~praman1/static/pub/dsmlr_KDD19_slides_short.pdf"
          style="color:#FF0000">Slides</a> </li>
    <li style="padding: 5px 5px;"> 
        04/2019: Work on <span style="background:
        #eeffee"> Scaling Multinomial Logistic Regression via Hybrid-Parallelism </span> 
        accepted as Oral Presentation to <a
                                          href="https://www.kdd.org/kdd2019/">KDD
                                          2019</a>, Anchorage, Alaska. </li>
    <li style="padding: 5px 5px;"> 
        04/2019: Presented work on <span style="background:
        #eeffee"> Extreme Stochastic Variational Inference (ESVI): Distributed
        Inference for Large-Scale Mixture Models </span> at <a
                                          href="https://www.aistats.org/">AISTATS
                                          2019</a>, Okinawa, Japan. </li>
    <li style="padding: 5px 5px;"> 
        07/2018: Attended <a href="https://ifds.wisc.edu/workshops/fundamentals/">Fundamentals of
      Data Analysis </a> (Summer School at TRIPODS Institute, UW Madison) </li>
    <li style="padding: 5px 5px;"> 
        07/2018: Guest Lecture on <span style="background:
        #eeffee"> Recipes For PhD - A Machine Learning Perspective </span>, 
            PSG Tech, Coimbatore, <a href="static/pub/phd_recipes.pdf">Slides </a></li>
    <li style="padding: 5px 5px;"> 
        05/2018: Guest Lecture on <span style="background: #eeffee"> Distributed
        Machine Learning: Approaches and Challenges </span>
        for AMS 250 (High Performance Computing course), UC Santa Cruz, <a
        href="static/pub/DistribML_Challenges&Approaches_Params.pdf">Slides</a> </li>
</ul>

<!--hr>
<small>A fun counter, showing the distribution of visitors to my homepage!</small>
<a href="https://info.flagcounter.com/CjLd"><img
src="https://s04.flagcounter.com/count2/CjLd/bg_FFFFFF/txt_000000/border_CCCCCC/columns_5/maxflags_50/viewers_0/labels_1/pageviews_1/flags_0/percent_0/"
alt="Flag Counter" border="0"></a-->
